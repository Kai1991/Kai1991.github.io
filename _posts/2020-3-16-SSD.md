---
layout:     post
title:      SSD总结
subtitle:   SSD
date:       2020-03-16
author:     Kai
header-img: img/home-bg-o.jpg
catalog: true
tags:
    -  SSD 
    -  检测
---

SSD 是经典的one-stage方法，这篇记录对SSD的认识。这篇是基于[SSD Pytorch版本](https://github.com/lufficc/SSD)代码 

## 1.模型结构
<img src="{{ site.baseurl }}/img/2020-3-16-SSD/SSD_str.png" /> 
SSD的Backbone在VGG的基础上增加了8个额外的特征图，同时使用FPN结构 提取如下特征送入BoxHead参与分类和回归

- Batch_size ,512,32,32 
- Batch_size ,1024,19,19 
- Batch_size ,512,10,10 
- Batch_size ,256,5,5 
- Batch_size ,256,3,3 
- Batch_size ,256,1,1 

### 1.1.Backbone 特征提取

#### 1.1.1.VGG
作者在Vgg第五层之后删除全连接层，增加两层卷积：1024x3x3、1024x1x1 达到 stage7
这里的VGG 结构是：

- stage_1 2层卷积  shape:  bash_size,64,150,150
- stage_2 2层卷积  shape:  bash_size,128,75,75
- stage_3 3层卷积  shape:  bash_size,256,38,38
- stage_4 3层卷积  shape:  bash_size,512,19,19
- stage_5 3层卷积  shape:  bash_size,512,19,19
- stage_6 1层卷积  shape:  bash_size,512,19,19
- stage_7 1层卷积  shape:  bash_size,512,19,19

都是通过maxPool 压缩特征图的,stage_6,stage_7之后没有使用maxpool
* 注：stage_3后的maxpool 参数 ceil_mode=True,使得输出为 38x38
* 注：stage_5后的maxpool 参数 3x3 stride = 1,使得输出为 19,19
#### 1.1.2.Extra Layers
<img src="{{ site.baseurl }}/img/2020-3-16-SSD/ExtraLayers.jpg" />
vgg 之后增加 4层stage ：stage_8 - stage_11, 每层stage 都是两层卷积，这里通过卷积进行下采样

- stage_8  2层卷积  shape:  bash_size,512,10,10
- stage_9  2层卷积  shape:  bash_size,256,5,5
- stage_10 2层卷积  shape:  bash_size,256,3,3
- stage_11 2层卷积  shape:  bash_size,256,1,1

#### 1.1.3.FPN
这里提取了6份特征图

- feature_1 shape: 512, 38, 38   位置：23层 stage_4最后卷积之后
- feature_2 shape: 1024, 19, 19  位置：stage_7 最后卷积之后
- feature_3 shape: 512, 10, 10   位置：stage_8 最后卷积之后
- feature_4 shape: 256, 5, 5     位置：stage_9 最后卷积之后
- feature_5 shape: 256, 3, 3     位置：stage_10 最后卷积之后
- feature_6 shape: 256, 1, 1     位置：stage_11 最后卷积之后

* 注：每个特征图的feature cell 对应先验框的数量：4，6，6，6，4，4

### 1.2.BoxHead

前面提取之后每个特征图都要经过 分类 和 回归。 这里就是BoxPredictor的功能

#### 1.2.1.BoxPredictor
循环遍历得到 置信度和 位置回归信息。这里模型结构，执行度没什么好说的，重点说一下位置回归信息

<img src="{{ site.baseurl }}/img/2020-3-16-SSD/BoxHead.jpg" />


#### 1.2.2.MultiBoxLoss
分类损失使用的是交叉熵损失，位置回归使用的是smoothL1Loss 与fasterRCNN一样，没啥好说的，这里说一下 hard negative mining。一开始对下面代码不是很懂，不明白其含义
```
loss = -F.log_softmax(confidence,dim=2)[:,:,0]
mask = hard_negative_mining(loss, labels, self.neg_pos_ratio)
```
先说以下这行计算loss:
- 前面家负号原因是softmax的结果是0-1之间，log 之后是负数，所以加个负号，为正值
- 这里是计算每个框是背景产生损失有的多大， [:,:,0] 所以只看0位置麻。
计算完损失后在说一下hard negative mining 
- 问题：生成的边框太多约8千，背景框占到绝大部分，与真值有关的框说200附近，所与需要剔除绝大多数背景框，
- 使用带来损失比较大的背景框 同时 前景：背景比例保持在 1：3

## 2.先验框生成
面积，长宽比决定先验框

- 面积遵守一个线性递增规则，随着特征图大小降低，先验框线性增加 
<img src="{{ site.baseurl }}/img/2020-3-16-SSD/box_fun.svg" />

其中：
* m是特征图个数，但是为5，第一层是单独设置的
* s是先验框大小相对于图片的尺寸，最小取0.2,最大取0.

## 4.训练细节
