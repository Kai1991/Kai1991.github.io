---
layout:     post
title:      SSD总结
subtitle:   SSD
date:       2020-03-16
author:     Kai
header-img: img/home-bg-o.jpg
catalog: true
tags:
    -  SSD 
    -  检测
---

SSD 是经典的one-stage方法，这篇记录对SSD的认识。这篇是基于[SSD Pytorch版本](https://github.com/lufficc/SSD)代码 

## 1.模型结构
<img src="{{ site.baseurl }}/img/2020-3-16-SSD/SSD_str.png" /> 
SSD的Backbone在VGG的基础上增加了8个额外的特征图，同时使用FPN结构 提取如下特征送入BoxHead参与分类和回归

- Batch_size ,512,32,32 
- Batch_size ,1024,19,19 
- Batch_size ,512,10,10 
- Batch_size ,256,5,5 
- Batch_size ,256,3,3 
- Batch_size ,256,1,1 

### 1.1.Backbone 特征提取

#### 1.1.1.VGG
作者在Vgg第五层之后删除全连接层，增加两层卷积：1024x3x3、1024x1x1 达到 stage7
这里的VGG 结构是：

- stage_1 2层卷积  shape:  bash_size,64,150,150
- stage_2 2层卷积  shape:  bash_size,128,75,75
- stage_3 3层卷积  shape:  bash_size,256,38,38
- stage_4 3层卷积  shape:  bash_size,512,19,19
- stage_5 3层卷积  shape:  bash_size,512,19,19
- stage_6 1层卷积  shape:  bash_size,512,19,19
- stage_7 1层卷积  shape:  bash_size,512,19,19

都是通过maxPool 压缩特征图的,stage_6,stage_7之后没有使用maxpool
* 注：stage_3后的maxpool 参数 ceil_mode=True,使得输出为 38x38
* 注：stage_5后的maxpool 参数 3x3 stride = 1,使得输出为 19,19
#### 1.1.2.Extra Layers
<img src="{{ site.baseurl }}/img/2020-3-16-SSD/ExtraLayers.jpg" />
vgg 之后增加 4层stage ：stage_8 - stage_11, 每层stage 都是两层卷积，这里通过卷积进行下采样

- stage_8  2层卷积  shape:  bash_size,512,10,10
- stage_9  2层卷积  shape:  bash_size,256,5,5
- stage_10 2层卷积  shape:  bash_size,256,3,3
- stage_11 2层卷积  shape:  bash_size,256,1,1

#### 1.1.3.FPN
这里提取了6份特征图

- feature_1 shape: 512, 38, 38   位置：23层 stage_4最后卷积之后
- feature_2 shape: 1024, 19, 19  位置：stage_7 最后卷积之后
- feature_3 shape: 512, 10, 10   位置：stage_8 最后卷积之后
- feature_4 shape: 256, 5, 5     位置：stage_9 最后卷积之后
- feature_5 shape: 256, 3, 3     位置：stage_10 最后卷积之后
- feature_6 shape: 256, 1, 1     位置：stage_11 最后卷积之后

* 注：每个特征图的feature cell 对应先验框的数量：4，6，6，6，4，4

### 1.2.BoxHead

前面提取之后每个特征图都要经过 分类 和 回归。 这里就是BoxPredictor的功能

#### 1.2.1.BoxPredictor
循环遍历得到 置信度和 位置回归信息。这里模型结构，执行度没什么好说的，重点说一下位置回归信息

<img src="{{ site.baseurl }}/img/2020-3-16-SSD/BoxHead.jpg" />


#### 1.2.2.MultiBoxLoss
分类损失使用的是交叉熵损失，位置回归使用的是smoothL1Loss 与fasterRCNN一样，没啥好说的，这里说一下 hard negative mining。一开始对下面代码不是很懂，不明白其含义
```
loss = -F.log_softmax(confidence,dim=2)[:,:,0]
mask = hard_negative_mining(loss, labels, self.neg_pos_ratio)
```
先说以下这行计算loss:
- 前面家负号原因是softmax的结果是0-1之间，log 之后是负数，所以加个负号，为正值
- 这里是计算每个框是背景产生损失有的多大， [:,:,0] 所以只看0位置麻。
计算完损失后在说一下hard negative mining 
- 问题：生成的边框太多约8千，背景框占到绝大部分，与真值有关的框说200附近，所与需要剔除绝大多数背景框，
- 使用带来损失比较大的背景框 同时 前景：背景比例保持在 1：3
- 两次sort ,能够得到每个元素在降序中的idx_rank
<img src="{{ site.baseurl }}/img/2020-3-16-SSD/rank.jpg" />

## 2.先验框生成
面积，长宽比决定先验框

- 面积遵守一个线性递增规则，随着特征图大小降低，先验框线性增加 
<img src="{{ site.baseurl }}/img/2020-3-16-SSD/box_fun.svg" />

其中：
* m是特征图个数，但是为5，第一层是单独设置的
* s是先验框大小相对于图片的尺寸，最小取0.2,最大取0.

对于第一个特征图，先验框的尺度比例是 s_min/2 = 0.1 也就是 300 x 0.1 = 30
根据上面公式，先扩大一百倍，计算出来值然后除以100 ，然后乘以300 得到最终面积是 30，60，111，162，213，264
先验框的长宽比是： 1，2，3，1/2，1/3
根据面积和长宽比得到长宽：
<img src="{{ site.baseurl }}/img/2020-3-16-SSD/w_and_l.svg" />
还要增加一个特殊面积 ：[公式]
但是第一个和最后两个特征图不使用长宽比：3，1/3的
所以特征图先验框个数是 4，6，6，6，4，4
总个数是： 38x38x4+19x19x6+10x10x6+5x5x6+3x3x4+1x1x4=8732

## L2 正则化
VGG 网络的Conv4_3的特征图是38x38 网络层靠前，norm较大，需要加上一个L2 Normalization ,以保证和后面的检测层差异不是很大

```
class L2Norm(nn.Module):
    '''
    conv4_3特征图大小38x38，网络层靠前，norm较大，需要加一个L2 Normalization,
    以保证和后面的检测层差异不是很大，具体可以参考： ParseNet。
    '''
    def __init__(self, n_channels, scale):
        super(L2Norm, self).__init__()
        self.n_channels = n_channels
        self.gamma = scale or None
        self.eps = 1e-10
        # 将一个不可训练的类型Tensor转换成可以训练的类型 parameter
        self.weight = nn.Parameter(torch.Tensor(self.n_channels))
        self.reset_parameters()

    # 初始化参数    
    def reset_parameters(self):
        nn.init.constant_(self.weight, self.gamma)

    def forward(self, x):
        # 计算 x 的2范数，参考公式 (2)
        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt() # shape[b,1,38,38]

        # 参考公式 (1)
        x = x / norm   # shape[b,512,38,38]

        # 扩展self.weight的维度为shape[1,512,1,1]，然后参考公式
        out = self.weight[None,...,None,None] * x

        return out
```

## 位置编码和解码
- 先验框 <img src="{{ site.baseurl }}/img/2020-3-16-SSD/anchor.svg" />
- 真实框 <img src="{{ site.baseurl }}/img/2020-3-16-SSD/box.svg" />
- variance 用于调节检测值

### 编码
得到预测框相对于先验框的偏移量 及：偏移多少，缩放多少
